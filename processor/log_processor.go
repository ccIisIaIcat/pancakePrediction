package processor

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"math/big"
	"strings"
	"sync"
	"time"

	"github.com/ccIisIaIcat/pancakePrediction/common/types"
	"github.com/ccIisIaIcat/pancakePrediction/contracts"
	"github.com/ethereum/go-ethereum/accounts/abi"
	"github.com/ethereum/go-ethereum/common"
	ethtypes "github.com/ethereum/go-ethereum/core/types"
)

// LogProcessor æ—¥å¿—å¤„ç†å™¨,æ”¯æŒå¤šä¸ª WebSocket æºå’Œå»é‡
type LogProcessor struct {
	mu            sync.RWMutex
	txHashCache   map[string]time.Time // äº¤æ˜“ hash -> è¿‡æœŸæ—¶é—´
	cacheExpiry   time.Duration
	contractABI   abi.ABI
	eventCallback func(*types.LogResult, string, map[string]interface{}, string) // å›è°ƒå‡½æ•°: (æ—¥å¿—, äº‹ä»¶å, è§£æåçš„å‚æ•°, endpoint)
}

// NewLogProcessor åˆ›å»ºæ—¥å¿—å¤„ç†å™¨
func NewLogProcessor(cacheExpiry time.Duration) (*LogProcessor, error) {
	// è§£æåˆçº¦ ABI
	contractABI, err := abi.JSON(strings.NewReader(contracts.PancakePredictionMetaData.ABI))
	if err != nil {
		return nil, fmt.Errorf("failed to parse ABI: %w", err)
	}

	return &LogProcessor{
		txHashCache:   make(map[string]time.Time),
		cacheExpiry:   cacheExpiry,
		contractABI:   contractABI,
		eventCallback: defaultEventCallback,
	}, nil
}

// SetEventCallback è®¾ç½®è‡ªå®šä¹‰äº‹ä»¶å›è°ƒå‡½æ•°
func (p *LogProcessor) SetEventCallback(callback func(*types.LogResult, string, map[string]interface{}, string)) {
	p.eventCallback = callback
}

// ProcessLogMessage å¤„ç†æ—¥å¿—æ¶ˆæ¯(å¸¦å»é‡)
func (p *LogProcessor) ProcessLogMessage(rawMessage []byte, endpoint string) error {
	// è§£ææ¶ˆæ¯
	var notification types.EthSubscriptionNotification
	if err := json.Unmarshal(rawMessage, &notification); err != nil {
		return fmt.Errorf("failed to unmarshal notification: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦ä¸º eth_subscription æ¶ˆæ¯
	if notification.Method != "eth_subscription" {
		return nil
	}

	logResult := &notification.Params.Result
	txHash := logResult.TransactionHash

	// å»é‡æ£€æŸ¥
	if p.isDuplicate(txHash) {
		log.Printf("â­ï¸  [%s] Skipping duplicate transaction: %s", endpoint, txHash)
		return nil
	}

	// æ ‡è®°ä¸ºå·²å¤„ç†
	p.markProcessed(txHash)

	// è§£æäº‹ä»¶
	eventName, eventData, err := p.parseEvent(logResult)
	if err != nil {
		log.Printf("âš ï¸  [%s] Failed to parse event: %v", endpoint, err)
		return err
	}

	// è°ƒç”¨å›è°ƒå‡½æ•°
	if p.eventCallback != nil {
		p.eventCallback(logResult, eventName, eventData, endpoint)
	}

	return nil
}

// isDuplicate æ£€æŸ¥äº¤æ˜“æ˜¯å¦å·²å¤„ç†(å¸¦è¿‡æœŸæ¸…ç†)
func (p *LogProcessor) isDuplicate(txHash string) bool {
	p.mu.Lock()
	defer p.mu.Unlock()

	// æ¸…ç†è¿‡æœŸç¼“å­˜
	now := time.Now()
	for hash, expiry := range p.txHashCache {
		if now.After(expiry) {
			delete(p.txHashCache, hash)
		}
	}

	// æ£€æŸ¥æ˜¯å¦å­˜åœ¨
	_, exists := p.txHashCache[txHash]
	return exists
}

// markProcessed æ ‡è®°äº¤æ˜“ä¸ºå·²å¤„ç†
func (p *LogProcessor) markProcessed(txHash string) {
	p.mu.Lock()
	defer p.mu.Unlock()
	p.txHashCache[txHash] = time.Now().Add(p.cacheExpiry)
}

// parseEvent è§£æäº‹ä»¶
func (p *LogProcessor) parseEvent(logResult *types.LogResult) (string, map[string]interface{}, error) {
	if len(logResult.Topics) == 0 {
		return "", nil, fmt.Errorf("no topics in log")
	}

	// æ„é€  go-ethereum çš„ Log ç±»å‹
	topics := make([]common.Hash, len(logResult.Topics))
	for i, topic := range logResult.Topics {
		topics[i] = common.HexToHash(topic)
	}

	ethLog := ethtypes.Log{
		Address: common.HexToAddress(logResult.Address),
		Topics:  topics,
		Data:    common.FromHex(logResult.Data),
	}

	// æ ¹æ® topic[0] æŸ¥æ‰¾äº‹ä»¶
	eventSig := topics[0]
	event, err := p.contractABI.EventByID(eventSig)
	if err != nil {
		return "", nil, fmt.Errorf("unknown event signature %s: %w", eventSig.Hex(), err)
	}

	// è§£æäº‹ä»¶æ•°æ®
	eventData := make(map[string]interface{})
	if err := p.contractABI.UnpackIntoMap(eventData, event.Name, ethLog.Data); err != nil {
		return "", nil, fmt.Errorf("failed to unpack event data: %w", err)
	}

	// è§£æç´¢å¼•å‚æ•°(topics)
	if len(topics) > 1 {
		indexedArgs := make([]abi.Argument, 0)
		for _, arg := range event.Inputs {
			if arg.Indexed {
				indexedArgs = append(indexedArgs, arg)
			}
		}

		if err := abi.ParseTopicsIntoMap(eventData, indexedArgs, topics[1:]); err != nil {
			return "", nil, fmt.Errorf("failed to parse indexed arguments: %w", err)
		}
	}

	return event.Name, eventData, nil
}

// StartCleanup å¯åŠ¨å®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜
func (p *LogProcessor) StartCleanup(ctx context.Context, interval time.Duration) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			p.cleanupExpiredCache()
		}
	}
}

// cleanupExpiredCache æ¸…ç†è¿‡æœŸç¼“å­˜
func (p *LogProcessor) cleanupExpiredCache() {
	p.mu.Lock()
	defer p.mu.Unlock()

	now := time.Now()
	count := 0
	for hash, expiry := range p.txHashCache {
		if now.After(expiry) {
			delete(p.txHashCache, hash)
			count++
		}
	}

	if count > 0 {
		log.Printf("ğŸ§¹ Cleaned up %d expired cache entries", count)
	}
}

// defaultEventCallback é»˜è®¤äº‹ä»¶å›è°ƒå‡½æ•°
func defaultEventCallback(logResult *types.LogResult, eventName string, eventData map[string]interface{}, endpoint string) {
	log.Printf("\nğŸ¯ Event Detected: %s", eventName)
	log.Printf("   ğŸ“¡ Source: %s", endpoint)
	log.Printf("   ğŸ“ Contract: %s", logResult.Address)
	log.Printf("   ğŸ“¦ Block: %s", logResult.BlockNumber)
	log.Printf("   ğŸ”— TxHash: %s", logResult.TransactionHash)
	log.Printf("   ğŸ“Š Event Data:")

	for key, value := range eventData {
		// æ ¼å¼åŒ–ä¸åŒç±»å‹çš„å€¼
		var formattedValue string
		switch v := value.(type) {
		case *big.Int:
			formattedValue = v.String()
		case common.Address:
			formattedValue = v.Hex()
		case []byte:
			formattedValue = common.Bytes2Hex(v)
		default:
			formattedValue = fmt.Sprintf("%v", v)
		}
		log.Printf("      â€¢ %s: %s", key, formattedValue)
	}
	log.Println()
}
